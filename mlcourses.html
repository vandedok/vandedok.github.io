<!DOCTYPE html>

<html>
<head>
<title>Free ML and DL courses</title>
</head>
<body>

<h1>Free ML and DL courses</h1>

<p> What is great about machine learning is a variety of
free courses with awesome lectures and exercises,
which can be done without a tutor.
</p>

<p>My opinion is that it's better to stick to the courses with
the exercises. Some of the courses below have them -- usually in
form of jupyter notebooks with supplementary
python modules. To solve the problem  you have to
run the notebook and to modify the code inside (or in the supplementary modules)
to make it working. The places where to modify the code are usually marked with
comments. Anyways, if there is a problem try to read the course contents
carefully -- the guidelines are usually nearby.
</p>

<p> While solving such tasks will not make you a great machine learner,
it's an awesome way to get some primary experience and to move
further.
</p>

<p> <strong> Disclaimer</strong> <br>
Some of the courses are in Russian. However it's possible that there are
English subs and the comments in the exercises are in English from the beginning.
</p>
<hr>
<h2> Glossary </h2>
<dl>
<dt>ML</dt>
<dd> Machine learning. Sometimes means all machine learning, but usually refers
to classical techniques, nowadays usually being used for structured (table) data
</dd>
<dt>DL</dt>
<dd>Deep learning. The best definition I know so far is "everything which learns"
with backpropogation algorithm
</dd>
<dt>CV</dt>
<dd>
Computer vision, the problems related to image or video data
</dd>
<dt>NLP</dt>
<dd>
Natural language processing. The problems related to natural --
 usually human -- languages
</dd>
<dt>RF</dt>
<dd>
Reinforcement learning. The framework, where some agent learns how to
act in a certain environment. You may think of at as "how to teach computer
play computer games"
</dd>
</dl>
<hr>

<h2>ml-mipt course</h2>

  <p>Great course from Moscow Institute of Physics and Technology (MIPT).
  One of two courses from there, actually.
  </p>

  <p> The course consists of two parts -- basic and advanced, which should be
  taken consequently. The basic part is about classical ML and also has
  an introduction to neural networks -- there is even a task to implement a backprop,
  but after that PyTorch is used. The second part is a decent introduction
  to NLP, RF and CV. Of course each of those worth a separate course, but these
  introductions are enough wide and deep to get the impression what's going on inside,
  to try most popular models and to understand if you are interested in the further study.
  </p>

  <p> The lectures and the seminars are in Russian, the problems are in English.
  For each part there are two sets of problems: hometasks, which are usually not
  hard to make, and labs, which may take a while to finish. The course
  contents is updated yearly.
  </p>

  <p><a href=https://ml-mipt.github.io/> Course page </a>
  <br>
  <a href=https://github.com/girafe-ai/ml-mipt> Course github (with slides and problems) </a>
  </p>

<h2>Vorontsov course</h2>

  <p>Another course from MIPT -- this one is considered to be with a stronger
  emphasis on theory. However both courses have theory and practice.
  </p>

  <p> This course consists of two parts: the first one is dedicated to
  mathematical foundations of ML, the second one to the applied problems.
  Actually, the division "classical ML/DL" more or less holds here.
  </p>

  <p> The front page, lectures and the seminars are in Russian. Some of
    the problems are located in Kaggle, others are given in text form.
  </p>

  <p><a href=https://bit.ly/1bCmE3Z> Course page </a>
  <br>
  <a href=https://github.com/andriygav/MachineLearningSeminars> Seminars and problems </a>
  </p>

<h2>ODS.ai courses</h2>

<p>Awesome courses from <a href=https://ods.ai/> ods.ai</a> community. </p>

<p>There are two of them: one is for the classical ML, another is for deep learning.
The key feature is that in the second course -- dlcourse.ai -- it is not assumed
that you are familiar with classical ML, so you can start studying without
any preliminary knowledge and get your hands dirty with deep networks, CV, NLP and RF. However mlcourse.ai (the first one) is also worth
taking -- it's structure is somewhat different from the academic courses, maybe
because of the participation of the kaggle sportsmen from the community.

<p> mlcourse.ai is fully in English. dlcourse.ai is in Russian --
even the comments in jupyter notebooks. </p>

<p>
<a href=https://mlcourse.ai/> mlcourse.ai -- classical ML, English</a>
<br>
<a href=https://dlcourse.ai/> dlcourse.ai -- deep learning and applications, Russian</a>
</p>

<h2>CS229</h2>

<p>Probably the most famous ML course -- meet the CS229 from Stanford.</p>

The course is considered to be pretty theoretical and mostly about classical ML.
However there is some attention paid to applications.

The problems are not present in the main page of the course, however it's possible
to find them in github.

<p>
<a href=https://cs229.stanford.edu/> main course page</a>
<br>
<a href=http://cs229.stanford.edu/syllabus-summer2020.html> Course for summer 2020, with lecture notes and videos</a>
<br>
<a href=https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU> Andrew Ng course lectures (2018)</a>
<br>
<a href=https://github.com/ccombier/stanford-CS229> Problem sets with solutions, 2017</a>
<br>
<a href=https://github.com/huyfam/cs229-solutions-2020> Problem sets with solutions, 2020</a>
</p>
</body>
</html>
